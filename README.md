# Proyecto Integrador M2 - Data Engineering üöÄ

Este repositorio contiene la soluci√≥n completa al Proyecto Integrador del M√≥dulo 2 de la carrera de Data Engineering en Henry.

El objetivo fue construir un **Data Warehouse** para una plataforma de E-commerce, partiendo de archivos CSV crudos, pasando por un proceso de ingesta, limpieza y transformaci√≥n, hasta llegar a un modelo dimensional (Estrella) listo para ser consumido por herramientas de BI.

## üõ†Ô∏è Tecnolog√≠as Utilizadas
- **Python**: Para la ingesta de datos y scripts de control.
- **PostgreSQL**: Como motor de base de datos (Data Warehouse).
- **dbt (data build tool)**: Para la transformaci√≥n de datos, testing y documentaci√≥n.
- **SQL**: Para consultas de negocio y definiciones DDL.

## üìÇ Estructura del Proyecto
- `DB Proyecto/`: Archivos fuente (CSVs) y scripts SQL originales.
- `pi_m2_dbt/`: Directorio principal del proyecto dbt.
  - `models/staging`: Capa de limpieza y estandarizaci√≥n (Vistas).
  - `models/intermediate`: L√≥gica de negocio y pre-joins.
  - `models/marts`: Tablas de Hechos y Dimensiones finales.
  - `snapshots`: **SCD Tipo 2** para historizar cambios en Usuarios y Productos.
- `queries/`: Respuestas SQL a las preguntas de negocio planteadas.
- `docs/`: Documentaci√≥n de dise√±o (Bus Matrix, Diagrama ER).
- `scripts/`: Scripts auxiliares (Carga inicial, EDA).

## ‚öôÔ∏è Configuraci√≥n y Ejecuci√≥n

### 1. Prerrequisitos
Tener instalado Python 3.x, PostgreSQL y Git.

### 2. Configuraci√≥n del Entorno
1. Clonar el repositorio.
2. Crear y activar un entorno virtual:
   ```bash
   python -m venv venv
   # Windows
   .\venv\Scripts\activate
   # Mac/Linux
   source venv/bin/activate
   ```
3. Instalar dependencias:
   ```bash
   pip install -r requirements.txt
   ```
4. Configurar variables de entorno:
   Crear un archivo `.env` en la ra√≠z (basado en el ejemplo) con las credenciales de la base de datos para que funcionen los scripts de carga.

### 3. Carga de Datos (Ingesta)
Si la base de datos est√° vac√≠a, ejecutar el script de carga inicial:
```bash
python scripts/load_raw_data.py
```
*Esto leer√° los CSVs de `DB Proyecto/csv` y poblar√° las tablas raw en Postgres.*

### 4. Transformaci√≥n con dbt
Navegar a la carpeta del proyecto dbt:
```bash
cd pi_m2_dbt
```

Ejecutar los siguientes comandos en orden:
```bash
# Instalar dependencias (si las hubiera)
dbt deps

# Crear los snapshots (Importante para SCD Tipo 2)
dbt snapshot

# Correr los modelos (Staging -> Intermediate -> Marts)
dbt run

# Ejecutar los tests de calidad de datos
dbt test
```

### 5. Documentaci√≥n
Para ver el linaje de datos y la documentaci√≥n generada:
```bash
dbt docs generate
dbt docs serve
```

## üìù Notas de Dise√±o
- **SCD Tipo 2**: Decid√≠ implementar *Slowly Changing Dimensions* Tipo 2 para las dimensiones de `Usuarios` y `Productos`. Esto permite analizar c√≥mo cambian los atributos (como precios o direcciones) a lo largo del tiempo sin perder la historia.
- **Testing**: Se agregaron tests de unicidad (`unique`), no nulos (`not_null`) e integridad referencial (`relationships`) para asegurar la calidad de los datos en la capa final.

---
*Proyecto realizado por [Tu Nombre] para Henry.*
